---
author: tmzh
categories:
- Artificial Intelligence
comments: true
date: "2023-03-15T12:00:00Z"
image: /images/2020-09-26-meta-learning.png
slug: 2023-03-15-generative-ai-and-what-lies-ahead
tags:
- chatGPT
- philosophy
title: Generative AI and what lies ahead
---
## Introduction
In 2021, I wrote about GPT-3 model. About a year later, OpenAI released ChatGPT which was based on GPT-3 but trained using Reinforcement Learning from Human Feedback (RLHF). And not just ChatGPT, StableDiffusion and Dall-E are pushing the boundaries of art, creating stunning visuals from mere textual descriptions. Beyond hobby projects, even professional ad agencies are exploring how to use AI such as in this [Coca Cola ad](https://youtu.be/951q69P0La) and [Crocs ad](https://twitter.com/nonmayorpete/status/163516240862815846) which apparently took only 28 minutes from an empty canvas to final product. Salesforce has announced a generative AI CRM technology called Einstein GPT. You have companies developing tools to let you design UI and build applications from simple text prompts.

![diagram.com](2023-03-14-09-38-09.gif)
Credits: https://diagram.com/

Suddenly the industry seems to be moving from a trickle to a deluge. A staple fear about hyper intelligence in the past few decades has been that there is no discernible limit to the extent of intelligence that a recursively self-improving AI could attain. However, in my opinion, these are unfounded speculations given how little we understand about the inner-workings of AI (more on this later). We tend to project our apprehensions and anthropocentric tendencies onto AI and assume that it would act as a sentient being would. Rather than worrying about superhuman intelligence, the immediate problem is that AI models are already good enough to disrupt human society.

## Near-term challenges 
### What does it mean for job market?
There is always a concern that the AI systems will replace human workers in a variety of industries, leading to job losses and economic disruption. Fears of job losses due to technology changes is not new. In the early 19th century, textile workers in England formed the Luddite movement to protest against the introduction of new textile technologies that threatened their jobs. Their paranoia turned out to be misguided as new technologies led to industry growth, creating new jobs and increasing productivity. However, it is also important to acknowledge that while new technologies can bring in new avenues of employment there will be displacements in existing employment patterns. It is important for us as individuals and society to be prepared for these changes and adapt accordingly.

### Death of art or reincarnation of art?

## Mid-term challenges

### Impact on Culture 
When I wrote about GPT-3, the salient features that caught my attention was that:

* Effectiveness of scale
* Languages can be a model of physical world 
* Emergent behaviors leading to Zero to few shot learning

However I only thought of GPT-3 as a precursor for things to come. But recent products that are built on top of it such as ChatGPT has shown that GPT-3 and similar Large Language Models (LLM) are already good enough. And good enough models are easy to use, so their adoption will only continue to grow. 

Large scale models are largely homogeneous, derived from very few foundation models; training data is lopsided and only represents a tiny percentage of languages. The embedded social and political factors in these models leads to entrenchment of pre-dominant value system. Anyone who has ever tried to translate across language trees can attest to the fact that a lot of meanings don't translate outside their cultural context. Prevalence of homogeneous LLMs in society can lead to a cultural confirmity where individual expression and differences are lost on all levels from the individual to society.

### Impact on Society and Culture
Human society evolves in a dynamic equilibrium with technology. Every technological revolution has also been a sociological inflection point, as society adjusts adjusts not just to the novelty of new inventions but revises its implicit assumptions about how things should be. 

The cognitive revolution (language & arts) that laid the foundation for civilization by bringing people together, also gave us myths, hero worship and kings. It took millennia for society at large to realize the shackles of such institutions and free itself from them. Similarly, the invention of the printing press brought about a new era of mass communication, but also led to the spread of propaganda and the manipulation of public opinion. With the rise of radio and television came new forms of propaganda and disinformation. With the internet and social media, we still haven't figured out coping mechanisms for fake news and large scale manipulation of public opinion. With generative AI, the same risks exists but on a scale and reach never seen before. As people become more familiar with these tools, they will begin to trust its judgment automatically. In place of a circumspect, seemingly biased humans who can be possibly wrong, we will have an infallible, impartial oracle telling us what is true. 

But can we ever know when it is true?

### Why we can never truly understand AI
The performance of a LLM model comes from their emergent behaviors rather than explicit instruction. As per DeepMind paper, "Despite their deployment into real world, these models are very much research prototypes that are poorly understood"

Furthermore the resources required for training such large scale models keeps it out of reach for many; commercial incentives lend very few reasons for companies to make their models transparent or to attend to any of these social externalities arising from their obscurity. 


