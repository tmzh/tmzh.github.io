<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Create Beautiful Paintings From Rough Sketches Using Stable diffusion - Ephemeral Dance Of Electrons</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="tmzh"><meta name=description content="Introduction When it comes to creating artwork, there are many Generative AI tools, but my favorite one is the vanilla Stable Diffusion. Since it is open source, an ecosystem of tools and techniques have sprouted around it. With it, you can train your own model, fine-tune existing models, or use countless other models trained and hosted by others.
But one of my favorite use case is to render rough sketches into much prettier artwork."><meta name=keywords content="blog,code,recreational"><meta name=generator content="Hugo 0.112.3 with theme even"><link rel=canonical href=https://tmzh.github.io/post/2023-05-16-paint-like-bob-ross-using-stable-diffusion/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css rel=stylesheet><meta property="og:title" content="Create Beautiful Paintings From Rough Sketches Using Stable diffusion"><meta property="og:description" content="Introduction When it comes to creating artwork, there are many Generative AI tools, but my favorite one is the vanilla Stable Diffusion. Since it is open source, an ecosystem of tools and techniques have sprouted around it. With it, you can train your own model, fine-tune existing models, or use countless other models trained and hosted by others.
But one of my favorite use case is to render rough sketches into much prettier artwork."><meta property="og:type" content="article"><meta property="og:url" content="https://tmzh.github.io/post/2023-05-16-paint-like-bob-ross-using-stable-diffusion/"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-05-16T12:00:00+00:00"><meta property="article:modified_time" content="2023-05-16T12:00:00+00:00"><meta itemprop=name content="Create Beautiful Paintings From Rough Sketches Using Stable diffusion"><meta itemprop=description content="Introduction When it comes to creating artwork, there are many Generative AI tools, but my favorite one is the vanilla Stable Diffusion. Since it is open source, an ecosystem of tools and techniques have sprouted around it. With it, you can train your own model, fine-tune existing models, or use countless other models trained and hosted by others.
But one of my favorite use case is to render rough sketches into much prettier artwork."><meta itemprop=datePublished content="2023-05-16T12:00:00+00:00"><meta itemprop=dateModified content="2023-05-16T12:00:00+00:00"><meta itemprop=wordCount content="767"><meta itemprop=keywords content="stable-diffusion,art,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Create Beautiful Paintings From Rough Sketches Using Stable diffusion"><meta name=twitter:description content="Introduction When it comes to creating artwork, there are many Generative AI tools, but my favorite one is the vanilla Stable Diffusion. Since it is open source, an ecosystem of tools and techniques have sprouted around it. With it, you can train your own model, fine-tune existing models, or use countless other models trained and hosted by others.
But one of my favorite use case is to render rough sketches into much prettier artwork."><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Ephemeral Dance Of Electrons</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/><li class=mobile-menu-item>Home</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tags/><li class=mobile-menu-item>Tags</li></a><a href=/categories/><li class=mobile-menu-item>Categories</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Ephemeral Dance Of Electrons</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>Home</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=/categories/>Categories</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Create Beautiful Paintings From Rough Sketches Using Stable diffusion</h1><div class=post-meta><span class=post-time>2023-05-16</span><div class=post-category><a href=/categories/generative-ai/>Generative AI</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><ul><li><a href=#introduction>Introduction</a></li><li><a href=#instructions>Instructions</a><ul><li><a href=#setup>Setup</a></li><li><a href=#drawing>Drawing</a></li></ul></li></ul></li></ul></nav></div></div><div class=post-content><h2 id=introduction>Introduction</h2><p>When it comes to creating artwork, there are many Generative AI tools, but my favorite one is the vanilla <a href=https://github.com/CompVis/stable-diffusion>Stable Diffusion</a>. Since it is open source, an ecosystem of tools and techniques have sprouted around it. With it, you can train your own model, fine-tune existing models, or use countless other models trained and hosted by others.</p><p>But one of my favorite use case is to render rough sketches into much prettier artwork. In this post we will see how to setup real-time rendering so that we have an interactive drawing experience. See below to see how quickly we can come up with a decent painting.</p><p><img src=/images/2023-05-16-stable-diffusion-art.gif alt="Interactive drawing"></p><p>This was just a rough draft done in 2 minutes, with a bit more skill and persistence it is possible to extract a more beautiful artwork as per your want.</p><p><img src=/images/2023-05-16-stable-diffusion-art.png alt=Mountain></p><p>What I like about this approach is that it is interactive - you don&rsquo;t go in with a pre-conceived notion. You take your artwork to where the canvas (Stable Diffusion in this case) leads you. Next we will see how to set it up on your own.</p><h2 id=instructions>Instructions</h2><p>For this, I made use of the excellent <a href=https://github.com/AUTOMATIC1111/stable-diffusion-webui>Stable Diffusion web UI</a> project by AUTOMATIC1111. The Web UI also supports an API mode which we will use to generate images using <code>img2img</code> feature of Stable Diffusion. <code>img2img</code> uses the weights from Stable Diffusion to generate new images from an input image using <a href=https://replicate.com/stability-ai/stable-diffusion-img2img>StableDiffusionImg2ImgPipeline</a>.</p><blockquote><p>Ideally you would require a GPU with more than 8GB VRAM. There are workarounds to run the model on lower end GPUs. Refer to AUTOMATIC1111 docs or wiki for more details.</p></blockquote><h3 id=setup>Setup</h3><ol><li>Install Stable Diffusion Web UI by following the <a href=https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs#windows-method-1>instructions</a> in the project page. If you are on Windows, I would recommend running this directly on Windows rather than on WSL2. Navigating CUDA runtime dependencies across Windows + linux is not worth the time.</li><li>We would also need Jupyter notebook and webuiapi packages to call Stable Diffusion Web UI API. At launch, AUTOMATIC1111 always sets up a VirtualEnv and pip installs the packages from <code>requirements.txt</code>. So add the packages <code>notebook</code> and <code>webuiapi</code> to the bottom of <code>requirements.txt</code> present at the project root. Jupyter notebook package will get installed at the next launch.</li><li>Next we need to <a href=https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/API>enable</a> API support. For example, if you&rsquo;re using Windows, edit the <code>webui-user.bat</code> file and add &ndash;api &ndash;api-log to the COMMANDLINE_ARGS line:</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bat data-lang=bat><span class=line><span class=cl><span class=c1>Rem Stable diffusion webui</span>
</span></span><span class=line><span class=cl><span class=k>call</span> webui.bat
</span></span></code></pre></td></tr></table></div></div><ol start=4><li>Run the modified execution script. For example, on Windows, run <code>webui-user.bat</code>. It should launch Stable diffusion web UI</li><li>In order to run Jupyter notebook, open a separate CMD shell, activate the venv and then launch jupyter notebook</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1>## Activate venv</span>
</span></span><span class=line><span class=cl>venv<span class=se>\S</span>cripts<span class=se>\a</span>ctivate.bat 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## Run Jupyter notebook</span>
</span></span><span class=line><span class=cl>start jupyter notebook
</span></span></code></pre></td></tr></table></div></div><ol start=6><li>Verify that Stable Diffusion Web UI is running by visiting http://localhost:7860/ in your browser.</li><li>When you are done, remember to close both the CMD windows.</li></ol><h3 id=drawing>Drawing</h3><ol><li>Open a new notebook and add the following code:</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>webuiapi</span>  
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>IPython.display</span> <span class=kn>import</span> <span class=n>clear_output</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># create API client</span>
</span></span><span class=line><span class=cl><span class=n>api</span> <span class=o>=</span> <span class=n>webuiapi</span><span class=o>.</span><span class=n>WebUIApi</span><span class=p>(</span><span class=n>sampler</span><span class=o>=</span><span class=s1>&#39;Euler a&#39;</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>file_base</span> <span class=o>=</span> <span class=s2>&#34;base.png&#34;</span>
</span></span><span class=line><span class=cl><span class=n>file_prompt</span> <span class=o>=</span> <span class=s2>&#34;prompt.txt&#34;</span>
</span></span><span class=line><span class=cl><span class=n>f_base_new</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>f_prompt_new</span> <span class=o>=</span> <span class=mi>0</span> 
</span></span></code></pre></td></tr></table></div></div><ol start=2><li>Add your desired prompt text to the file <code>prompt.txt</code>. In my example above, I used a very generic prompt like below:</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>an oil painting of a scenery by bob ross
</span></span></code></pre></td></tr></table></div></div><ol start=3><li><p>Create a PNG file called <code>base.png</code> using MS Paint or any of your favorite image editing tool and save it at the base path.</p></li><li><p>Run this code from a new cell block in your notebook. It will monitor you files for changes periodically andcall Stable Diffusion web UI API to generate new images based on your updated drawings.</p></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>f_base</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>getmtime</span><span class=p>(</span><span class=n>file_base</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>f_prompt</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>getmtime</span><span class=p>(</span><span class=n>file_prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>f_base</span> <span class=o>==</span> <span class=n>f_base_new</span> <span class=ow>and</span> <span class=n>f_prompt</span><span class=o>==</span><span class=n>f_prompt_new</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>f_base_new</span> <span class=o>=</span> <span class=n>f_base</span>
</span></span><span class=line><span class=cl>        <span class=n>f_prompt_new</span> <span class=o>=</span> <span class=n>f_prompt</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_txt</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=n>file_prompt</span><span class=p>)</span><span class=o>.</span><span class=n>read_text</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>file_base</span><span class=p>)</span> <span class=k>as</span> <span class=n>im</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>result2</span> <span class=o>=</span> <span class=n>api</span><span class=o>.</span><span class=n>img2img</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>images</span><span class=o>=</span><span class=p>[</span><span class=n>im</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>                <span class=n>prompt</span><span class=o>=</span><span class=n>prompt_txt</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>negative_prompt</span> <span class=o>=</span> <span class=s2>&#34;poorly drawn, photorealistic, watermark, logo, text, bad anatomy, missing fingers,missing body part,mangled hands, NSFW&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>steps</span><span class=o>=</span><span class=mi>40</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>seed</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>styles</span><span class=o>=</span><span class=p>[],</span>
</span></span><span class=line><span class=cl>                <span class=n>cfg_scale</span><span class=o>=</span><span class=mi>7</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>width</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>height</span><span class=o>=</span><span class=mi>724</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>denoising_strength</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>clear_output</span><span class=p>(</span><span class=n>wait</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>display</span><span class=p>(</span><span class=n>result2</span><span class=o>.</span><span class=n>image</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ol start=5><li>Draw some rough strokes and watch stable-diffusion interpret and render it as a painting. Each rendering may take few seconds depending on the GPU configuration.</li><li>You will have to save the file periodically to trigger the <code>img2img</code> inference. If you are using a tool like Photoshop, you can turn on autosave.</li></ol></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>tmzh</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2023-05-16</span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/stable-diffusion/>stable-diffusion</a>
<a href=/tags/art/>art</a></div><nav class=post-nav><a class=next href=/post/2023-03-15-gpt-4-stable-diffusion-and-beyond/><span class="next-text nav-default">GPT-4, Stable Diffusion, and Beyond: How Generative AI Will Shape Human Society</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=social-links><a href=https://github.com/tmzh/tmzh.github.io class="iconfont icon-github" title=github></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2017 -
2023<span class=heart><i class="iconfont icon-heart"></i></span><span>tmzh</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script></body></html>